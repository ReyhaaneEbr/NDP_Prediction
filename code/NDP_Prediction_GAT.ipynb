{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hj9R3aEyAr2K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OWZ6uHGcuD"
      },
      "source": [
        "#GAT_ProtT5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Libraries"
      ],
      "metadata": {
        "id": "qiOcPIrAqYMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------\n",
        "# Load Required Libraries\n",
        "# ---------------------------------------\n",
        "\n",
        "# Install OGB (Open Graph Benchmark)\n",
        "!pip install ogb\n",
        "\n",
        "# Install PyTorch Geometric\n",
        "!pip install torch_geometric\n",
        "\n",
        "# Install PyTorch (if not already installed)\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "Z2e53OTAqU1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_curve,\n",
        "    auc\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import networkx as nx\n",
        "from scipy.sparse import coo_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from torch._C import *\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "MiEzhqlJcS_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj9R3aEyAr2K"
      },
      "source": [
        "##GAT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------\n",
        "# GAT Model Definition\n",
        "# ---------------------------------------\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes, num_layers, dropout):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.fc = torch.nn.ModuleList()\n",
        "\n",
        "        # First GAT layer\n",
        "        self.convs.append(GATConv(in_channels, hidden_channels))\n",
        "\n",
        "        # Intermediate GAT layers\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
        "\n",
        "        # Final GAT layer\n",
        "        self.convs.append(GATConv(hidden_channels, out_channels))\n",
        "\n",
        "        # Output fully connected layer\n",
        "        self.fc.append(torch.nn.Linear(out_channels, num_classes))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        # Apply GAT layers\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Apply fully connected layers (if more than one is used)\n",
        "        for fc in self.fc[:-1]:\n",
        "            x = fc(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Final layer\n",
        "        x = self.fc[-1](x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Training Function\n",
        "# ---------------------------------------\n",
        "\n",
        "def train(model, data, train_idx, optimizer):\n",
        "    model.train()\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)[train_idx]\n",
        "    loss = criterion(out, data.y[train_idx])\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Utility: One-Hot Encoding\n",
        "# ---------------------------------------\n",
        "\n",
        "def to_one_hot(y, num_classes):\n",
        "    y_one_hot = torch.zeros(y.size(0), num_classes).to(y.device)\n",
        "    y_one_hot.scatter_(1, y.view(-1, 1), 1)\n",
        "    return y_one_hot\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Evaluation Function (Train/Validation/Test)\n",
        "# ---------------------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, num_classes):\n",
        "    model.eval()\n",
        "\n",
        "    y_probs = model(data.x, data.adj_t)\n",
        "    y_probs = torch.softmax(y_probs, dim=1)\n",
        "\n",
        "    y_true_train = to_one_hot(data.y[split_idx['train']], num_classes)\n",
        "    y_true_valid = to_one_hot(data.y[split_idx['valid']], num_classes)\n",
        "    y_true_test = to_one_hot(data.y[split_idx['test']], num_classes)\n",
        "\n",
        "    def compute_metrics(y_true, y_probs):\n",
        "        y_pred_labels = y_probs.argmax(dim=1).cpu().numpy()\n",
        "        y_true_labels = y_true.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        acc = accuracy_score(y_true_labels, y_pred_labels)\n",
        "        prec = precision_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rec = recall_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        f1 = f1_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "\n",
        "        rocauc = roc_auc_score(y_true.cpu(), y_probs.cpu())\n",
        "\n",
        "        y_true_cpu = y_true.cpu()\n",
        "        y_true_binarized = label_binarize(y_true_cpu, classes=[0, 1])\n",
        "        y_probs_cpu = y_probs.cpu().numpy()\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(\n",
        "            y_true_binarized[:, 1],\n",
        "            [score[1] for score in y_probs_cpu]\n",
        "        )\n",
        "        auprc = auc(recall, precision)\n",
        "\n",
        "        return [acc, prec, rec, f1, rocauc, auprc]\n",
        "\n",
        "    train_metrics = compute_metrics(y_true_train, y_probs[split_idx['train']])\n",
        "    valid_metrics = compute_metrics(y_true_valid, y_probs[split_idx['valid']])\n",
        "    test_metrics = compute_metrics(y_true_test, y_probs[split_idx['test']])\n",
        "\n",
        "    return train_metrics, valid_metrics, test_metrics\n",
        "\n",
        "\n",
        "# ---------------------------------------\n",
        "# Evaluation Function for K-Fold Setting\n",
        "# ---------------------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_kfold(model, data, split_idx, num_classes):\n",
        "    model.eval()\n",
        "\n",
        "    y_probs = model(data.x, data.adj_t)\n",
        "    y_probs = torch.softmax(y_probs, dim=1)\n",
        "\n",
        "    y_true_train = to_one_hot(data.y[split_idx['train']], num_classes)\n",
        "    y_true_test = to_one_hot(data.y[split_idx['test']], num_classes)\n",
        "\n",
        "    def compute_metrics(y_true, y_probs):\n",
        "        y_pred_labels = y_probs.argmax(dim=1).cpu().numpy()\n",
        "        y_true_labels = y_true.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        acc = accuracy_score(y_true_labels, y_pred_labels)\n",
        "        prec = precision_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rec = recall_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        f1 = f1_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "\n",
        "        rocauc = roc_auc_score(y_true.cpu(), y_probs.cpu())\n",
        "\n",
        "        y_true_cpu = y_true.cpu()\n",
        "        y_true_binarized = label_binarize(y_true_cpu, classes=[0, 1])\n",
        "        y_probs_cpu = y_probs.cpu().numpy()\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(\n",
        "            y_true_binarized[:, 1],\n",
        "            [score[1] for score in y_probs_cpu]\n",
        "        )\n",
        "        auprc = auc(recall, precision)\n",
        "\n",
        "        return [acc, prec, rec, f1, rocauc, auprc]\n",
        "\n",
        "    train_metrics = compute_metrics(y_true_train, y_probs[split_idx['train']])\n",
        "    test_metrics = compute_metrics(y_true_test, y_probs[split_idx['test']])\n",
        "\n",
        "    return train_metrics, test_metrics\n"
      ],
      "metadata": {
        "id": "DTWrdCcrq796"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data"
      ],
      "metadata": {
        "id": "MsV1oQBFrrFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.read_csv('data/embeddings/protT5_embeddings.csv')\n",
        "df_labels = df_features.iloc[:4819, [0, -1]]\n",
        "df_labels.shape\n",
        "\n",
        "# Convert both ID columns to strings\n",
        "df_labels['Id'] = df_labels['Id'].astype(str)\n",
        "df_features['Id'] = df_features['Id'].astype(str)\n",
        "\n",
        "order_dict = {value: index for index, value in enumerate(list(df_labels['Id']))}\n",
        "\n",
        "def sorting_key(value):\n",
        "    return (order_dict.get(value, float('inf')), value)\n",
        "\n",
        "df_features = df_features.sort_values(by='Id', key=lambda x: x.map(sorting_key))\n",
        "df_features.shape\n",
        "\n",
        "\n",
        "\n",
        "graph_data = pd.read_csv('data/ppi_edges_iid.csv')\n",
        "id_list = list(df_features['Id'])\n",
        "\n",
        "G = nx.Graph()\n",
        "for id1, id2 in zip(list(graph_data.iloc[:,0]), list(graph_data.iloc[:,1])):\n",
        "    if (str(id1) in id_list) and (str(id2) in id_list):\n",
        "        G.add_edge(id1, id2)\n",
        "\n",
        "# Adding isolated nodes\n",
        "for node in df_features.iloc[:, 0]:\n",
        "    if node not in G.nodes():\n",
        "        G.add_node(node)\n",
        "\n",
        "len(G.edges)\n",
        "len(G.nodes())\n",
        "\n",
        "df_features = df_features[df_features['Id'].isin(list(G.nodes()))]\n",
        "\n",
        "adj_sparse = nx.adjacency_matrix(G, nodelist=list(df_features.iloc[:,0]))\n",
        "node_labels = np.array(df_features.iloc[:, -1])\n",
        "\n",
        "\n",
        "adj_matrix = coo_matrix(adj_sparse).todense()\n",
        "\n",
        "num_nodes = 4819\n",
        "num_features = 1024\n",
        "num_classes = 2\n",
        "\n",
        "node_features = np.array(df_features.iloc[:, 1:-1])\n",
        "node_names = np.array(df_features.iloc[:, 0])\n",
        "\n",
        "adj_matrix = (adj_matrix + adj_matrix.T) / 2\n",
        "adj_matrix[adj_matrix < 0.9] = 0\n",
        "\n",
        "node_features_tensor = torch.from_numpy(node_features).float()\n",
        "node_labels_tensor = torch.from_numpy(node_labels).long()\n",
        "\n",
        "adj_coo = adj_sparse.tocoo()\n",
        "indices = np.vstack((adj_coo.row, adj_coo.col))\n",
        "values = adj_sparse.data\n",
        "\n",
        "indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
        "values_tensor = torch.tensor(values, dtype=torch.float)\n",
        "\n",
        "adj_t = torch.sparse_coo_tensor(indices_tensor, values_tensor, adj_sparse.shape).to_sparse_csr()\n",
        "\n",
        "data = Data(uni_id=node_names, x=node_features_tensor, adj_t=adj_t, y=node_labels_tensor)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "id_to_idx_map = {id_: idx for idx, id_ in enumerate(data.uni_id)}\n",
        "\n",
        "def load_folds(folds_dir):\n",
        "    folds = []\n",
        "    for fold in range(1, 6):\n",
        "        train_path = os.path.join(folds_dir, f'fold_{fold}_train_ids.csv')\n",
        "        test_path = os.path.join(folds_dir, f'fold_{fold}_test_ids.csv')\n",
        "\n",
        "        train_ids = pd.read_csv(train_path)\n",
        "        test_ids = pd.read_csv(test_path)\n",
        "\n",
        "        train_idx = torch.tensor([id_to_idx_map[id_] for id_ in list(train_ids.iloc[:,0])],\n",
        "                                 dtype=torch.long).to(device)\n",
        "        test_idx = torch.tensor([id_to_idx_map[id_] for id_ in list(test_ids.iloc[:,0])],\n",
        "                                dtype=torch.long).to(device)\n",
        "\n",
        "        folds.append((train_idx, test_idx))\n",
        "\n",
        "    return folds\n",
        "\n",
        "folds_dir = \"data/folds/5_folds\"\n",
        "folds = load_folds(folds_dir)\n"
      ],
      "metadata": {
        "id": "3JHzlW2ArueA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu3uhp7LBG0D"
      },
      "source": [
        "##Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGAukhwOtjV5"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters and settings\n",
        "hidden_channels = 128\n",
        "out_channels = 64\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "runs = 5\n",
        "lr = 0.001\n",
        "epochs = 500\n",
        "eval_steps = 10\n",
        "log_steps = 10\n",
        "weights = torch.tensor([2.0,1.0])\n",
        "num_classes = 2\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load data and folds\n",
        "data = data.to(device)\n",
        "weights = weights.to(device)\n",
        "model = GAT(in_channels=data.num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=out_channels,\n",
        "            num_classes=num_classes,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout).to(device)\n",
        "\n",
        "# Metrics storage\n",
        "train_acc_list, train_prec_list, train_rec_list = [], [], []\n",
        "train_f1_list, train_rocauc_list, train_aucprc_list = [], [], []\n",
        "test_acc_list, test_prec_list, test_rec_list = [], [], []\n",
        "test_f1_list, test_rocauc_list, test_aucprc_list = [], [], []\n",
        "\n",
        "# Main training loop\n",
        "for fold, (train_idx, test_idx) in enumerate(folds):\n",
        "    print(f'\\n=== Fold {fold + 1}/{len(folds)} ===')\n",
        "    train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
        "    test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n",
        "    split_idx = {'train': train_idx, 'test': test_idx}\n",
        "\n",
        "    model.reset_parameters()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_train_rocauc = 0\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss = train(model, data, train_idx, optimizer)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if len(loss_history) > 10 and np.std(loss_history[-10:]) < 1e-3:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % eval_steps == 0 or epoch == epochs:\n",
        "            train_metrics, test_metrics = test_kfold(model, data, split_idx, num_classes)\n",
        "            train_rocauc = train_metrics[4]\n",
        "\n",
        "            # Save best model\n",
        "            if train_rocauc > best_train_rocauc:\n",
        "                best_train_rocauc = train_rocauc\n",
        "                torch.save(model.state_dict(), f'best_model_fold_{fold}.pt')\n",
        "\n",
        "    # Final evaluation with best model\n",
        "    model.load_state_dict(torch.load(f'best_model_fold_{fold}.pt'))\n",
        "    train_metrics, test_metrics = test_kfold(model, data, split_idx, num_classes)\n",
        "\n",
        "    # Store metrics\n",
        "    for lst, values in zip([train_acc_list, train_prec_list, train_rec_list, train_f1_list, train_rocauc_list, train_aucprc_list],\n",
        "                           train_metrics):\n",
        "        lst.append(values)\n",
        "\n",
        "    for lst, values in zip([test_acc_list, test_prec_list, test_rec_list, test_f1_list, test_rocauc_list, test_aucprc_list],\n",
        "                           test_metrics):\n",
        "        lst.append(values)\n",
        "\n",
        "# Metrics calculations\n",
        "def calculate_stats(metric_list, name):\n",
        "    return {\n",
        "        'mean': np.mean(metric_list),\n",
        "        'std': np.std(metric_list),\n",
        "        'var': np.var(metric_list),\n",
        "        'min': np.min(metric_list),\n",
        "        'max': np.max(metric_list)\n",
        "    }\n",
        "\n",
        "# Generate report\n",
        "print(\"\\n=== Final Report ===\")\n",
        "print(\"{:<15} {:<8} {:<8} {:<8} {:<8} {:<8}\".format(\n",
        "    'Metric', 'Mean', 'Std', 'Var', 'Min', 'Max'))\n",
        "\n",
        "for metric_name, train_list, test_list in [\n",
        "    ('Accuracy', train_acc_list, test_acc_list),\n",
        "    ('Precision', train_prec_list, test_prec_list),\n",
        "    ('Recall', train_rec_list, test_rec_list),\n",
        "    ('F1', train_f1_list, test_f1_list),\n",
        "    ('ROC AUC', train_rocauc_list, test_rocauc_list),\n",
        "    ('PR AUC', train_aucprc_list, test_aucprc_list)\n",
        "]:\n",
        "    train_stats = calculate_stats(train_list, 'Train')\n",
        "    test_stats = calculate_stats(test_list, 'Test')\n",
        "\n",
        "    print(f\"\\n**{metric_name}**\")\n",
        "    print(\"Train:\\t{mean:.4f} ± {std:.4f}\\t(var: {var:.4f})\\t[{min:.4f}-{max:.4f}]\".format(**train_stats))\n",
        "    print(\"Test:\\t{mean:.4f} ± {std:.4f}\\t(var: {var:.4f})\\t[{min:.4f}-{max:.4f}]\".format(**test_stats))"
      ]
    }
  ]
}